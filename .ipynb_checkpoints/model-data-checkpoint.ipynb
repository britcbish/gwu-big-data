{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Predictive Model(s)\n",
    "\n",
    "In this workbook, you will read the merged dataset you created previously and you will create transformer, estimators and pipelines to build a binary classification model to predict wether a trip has a tip or not.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "1. Read in your merged dataset\n",
    "2. Use transformes and encoders to perform feature engineering\n",
    "3. Split into training and testing\n",
    "4. Build `LogisticRegression` model(s) and train them using pipelines\n",
    "5. Evaluate the performance of the model(s) using `BinaryClassificationMetrics`\n",
    "\n",
    "You are welcome to add as many cells as you need below up until the next section. **You must include comments in your code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-61-69.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>assignment4-a2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f325b281630>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing and running spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"assignment4-a2\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the merged dataset from my s3 bucket\n",
    "dfMerged = spark.read\\\n",
    "  .format('parquet')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('s3://big-data-bucket-mine/dfMerged.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+-------------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+\n",
      "|           medallion|        hack_license|vendor_id|    pickup_datetime|rate_code|store_and_fwd_flag|   dropoff_datetime|passenger_count|trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|total_amount|\n",
      "+--------------------+--------------------+---------+-------------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+\n",
      "|00005007A9F30E289...|16780B3E72BAA7A5C...|      CMT|2013-03-27 19:49:35|        1|                 N|2013-03-27 19:53:00|              1|            204.0|          0.5|        -73.9915|      40.766277|        -73.98544|       40.768623|         CRD|        4.5|      1.0|    0.5|       1.2|         0.0|         7.2|\n",
      "|00005007A9F30E289...|16780B3E72BAA7A5C...|      CMT|2013-03-27 21:26:02|        1|                 N|2013-03-27 21:29:54|              1|            232.0|          0.7|       -73.99168|      40.739147|        -74.00111|        40.74468|         CSH|        5.0|      0.5|    0.5|       0.0|         0.0|         6.0|\n",
      "|00005007A9F30E289...|1E3F1640D7AE96FAD...|      CMT|2013-04-24 21:57:34|        1|                 N|2013-04-24 22:16:29|              1|           1135.0|          5.0|       -74.00161|      40.730717|        -73.95048|       40.780666|         CRD|       18.0|      0.5|    0.5|       3.8|         0.0|        22.8|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-09-30 08:18:49|        1|                 N|2013-09-30 08:25:29|              2|            399.0|          0.7|        -73.9709|       40.79809|         -73.9694|       40.790306|         CRD|        6.0|      0.0|    0.5|       1.3|         0.0|         7.8|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-07 14:24:19|        1|                 N|2013-10-07 14:41:14|              1|           1014.0|          0.9|       -73.97435|      40.762386|       -73.986595|       40.756054|         CSH|       11.0|      0.0|    0.5|       0.0|         0.0|        11.5|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-16 11:54:57|        1|                 N|2013-10-16 11:59:12|              1|            255.0|          0.6|       -73.96133|       40.78015|        -73.96265|       40.773636|         CRD|        5.0|      0.0|    0.5|       1.1|         0.0|         6.6|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-16 13:45:08|        1|                 N|2013-10-16 14:06:27|              2|           1278.0|          6.0|      -73.967064|      40.800983|        -73.97506|       40.741913|         CSH|       21.0|      0.0|    0.5|       0.0|         0.0|        21.5|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-11-06 13:25:34|        1|                 N|2013-11-06 13:38:43|              1|            788.0|          1.9|      -73.970535|       40.76072|        -73.98839|        40.74707|         CRD|       10.5|      0.0|    0.5|      2.75|         0.0|       13.75|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-11-11 11:55:49|        1|                 N|2013-11-11 12:24:06|              1|           1696.0|          3.4|      -73.978584|      40.751293|        -74.01028|       40.716774|         CRD|       19.5|      0.0|    0.5|       4.0|         0.0|        24.0|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-11-27 11:40:57|        1|                 N|2013-11-27 11:46:51|              1|            353.0|          0.7|       -74.00122|      40.720573|       -74.009155|        40.71363|         CRD|        5.5|      0.0|    0.5|       1.0|         0.0|         7.0|\n",
      "+--------------------+--------------------+---------+-------------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfMerged.show(10) #looking at the first 10 rows of data to ensure reading in the data worked properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a new column to show whether there is a tip included in the trip or not\n",
    "import pyspark.sql.functions as f\n",
    "dfMerged = dfMerged.withColumn(\"Tip?\", f.when(dfMerged[\"tip_amount\"] > 0, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.evaluation as ev\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.ml.regression as rg\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.ml.feature as feat\n",
    "import pyspark.ml.classification as cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+-------------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+----+-----------------+\n",
      "|           medallion|        hack_license|vendor_id|    pickup_datetime|rate_code|store_and_fwd_flag|   dropoff_datetime|passenger_count|trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|total_amount|Tip?|rate_code_encoded|\n",
      "+--------------------+--------------------+---------+-------------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+----+-----------------+\n",
      "|00005007A9F30E289...|16780B3E72BAA7A5C...|      CMT|2013-03-27 19:49:35|        1|                 N|2013-03-27 19:53:00|              1|            204.0|          0.5|        -73.9915|      40.766277|        -73.98544|       40.768623|         CRD|        4.5|      1.0|    0.5|       1.2|         0.0|         7.2|   1|  (239,[1],[1.0])|\n",
      "|00005007A9F30E289...|16780B3E72BAA7A5C...|      CMT|2013-03-27 21:26:02|        1|                 N|2013-03-27 21:29:54|              1|            232.0|          0.7|       -73.99168|      40.739147|        -74.00111|        40.74468|         CSH|        5.0|      0.5|    0.5|       0.0|         0.0|         6.0|   0|  (239,[1],[1.0])|\n",
      "|00005007A9F30E289...|1E3F1640D7AE96FAD...|      CMT|2013-04-24 21:57:34|        1|                 N|2013-04-24 22:16:29|              1|           1135.0|          5.0|       -74.00161|      40.730717|        -73.95048|       40.780666|         CRD|       18.0|      0.5|    0.5|       3.8|         0.0|        22.8|   1|  (239,[1],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-09-30 08:18:49|        1|                 N|2013-09-30 08:25:29|              2|            399.0|          0.7|        -73.9709|       40.79809|         -73.9694|       40.790306|         CRD|        6.0|      0.0|    0.5|       1.3|         0.0|         7.8|   1|  (239,[1],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-07 14:24:19|        1|                 N|2013-10-07 14:41:14|              1|           1014.0|          0.9|       -73.97435|      40.762386|       -73.986595|       40.756054|         CSH|       11.0|      0.0|    0.5|       0.0|         0.0|        11.5|   0|  (239,[1],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-16 11:54:57|        1|                 N|2013-10-16 11:59:12|              1|            255.0|          0.6|       -73.96133|       40.78015|        -73.96265|       40.773636|         CRD|        5.0|      0.0|    0.5|       1.1|         0.0|         6.6|   1|  (239,[1],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-16 13:45:08|        1|                 N|2013-10-16 14:06:27|              2|           1278.0|          6.0|      -73.967064|      40.800983|        -73.97506|       40.741913|         CSH|       21.0|      0.0|    0.5|       0.0|         0.0|        21.5|   0|  (239,[1],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-11-06 13:25:34|        1|                 N|2013-11-06 13:38:43|              1|            788.0|          1.9|      -73.970535|       40.76072|        -73.98839|        40.74707|         CRD|       10.5|      0.0|    0.5|      2.75|         0.0|       13.75|   1|  (239,[1],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-11-11 11:55:49|        1|                 N|2013-11-11 12:24:06|              1|           1696.0|          3.4|      -73.978584|      40.751293|        -74.01028|       40.716774|         CRD|       19.5|      0.0|    0.5|       4.0|         0.0|        24.0|   1|  (239,[1],[1.0])|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-11-27 11:40:57|        1|                 N|2013-11-27 11:46:51|              1|            353.0|          0.7|       -74.00122|      40.720573|       -74.009155|        40.71363|         CRD|        5.5|      0.0|    0.5|       1.0|         0.0|         7.0|   1|  (239,[1],[1.0])|\n",
      "+--------------------+--------------------+---------+-------------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+----+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using OneHotEncoderEstimator on Rate_Code to defferentiate between the regular rate and the high price rate\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "encoder = OneHotEncoderEstimator(inputCols=[\"rate_code\"],\n",
    "                                outputCols=[\"rate_code_encoded\"])\n",
    "modela = encoder.fit(dfMerged)\n",
    "dfMerged = modela.transform(dfMerged)\n",
    "dfMerged.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Using Bucketizer to divide latitudes and longitudes columns into buckers instead of numerical for easier categorical use in model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running bucketizer for pickup_longitude and adding it in the dataset\n",
    "splits = [-float(\"inf\"), 0, 5, float(\"inf\")]\n",
    "\n",
    "bucketizer = feat.Bucketizer(splits=splits, inputCol=\"pickup_longitude\", outputCol=\"pickup_longitude_bkt\")\n",
    "\n",
    "dfMerged = bucketizer.transform(dfMerged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running bucketizer for pickup_latitude and adding it in the dataset\n",
    "splits = [-float(\"inf\"), 0,5, float(\"inf\")]\n",
    "\n",
    "bucketizer = feat.Bucketizer(splits=splits, inputCol=\"pickup_latitude\", outputCol=\"pickup_latitude_bkt\")\n",
    "\n",
    "dfMerged = bucketizer.transform(dfMerged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running bucketizer for dropoff_longitude and adding it in the dataset\n",
    "splits = [-float(\"inf\"),0,5, float(\"inf\")]\n",
    "\n",
    "bucketizer = feat.Bucketizer(splits=splits, inputCol=\"dropoff_longitude\", outputCol=\"dropoff_longitude_bkt\")\n",
    "\n",
    "dfMerged = bucketizer.transform(dfMerged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running bucketizer for dropoff_latitude and adding it in the dataset\n",
    "splits = [-float(\"inf\"),0,5, float(\"inf\")]\n",
    "\n",
    "bucketizer = feat.Bucketizer(splits=splits, inputCol=\"dropoff_latitude\", outputCol=\"dropoff_latitude_bkt\")\n",
    "\n",
    "dfMerged = bucketizer.transform(dfMerged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+-------------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+----+-----------------+--------------------+-------------------+---------------------+--------------------+\n",
      "|           medallion|        hack_license|vendor_id|    pickup_datetime|rate_code|store_and_fwd_flag|   dropoff_datetime|passenger_count|trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|total_amount|Tip?|rate_code_encoded|pickup_longitude_bkt|pickup_latitude_bkt|dropoff_longitude_bkt|dropoff_latitude_bkt|\n",
      "+--------------------+--------------------+---------+-------------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+----+-----------------+--------------------+-------------------+---------------------+--------------------+\n",
      "|00005007A9F30E289...|16780B3E72BAA7A5C...|      CMT|2013-03-27 19:49:35|        1|                 N|2013-03-27 19:53:00|              1|            204.0|          0.5|        -73.9915|      40.766277|        -73.98544|       40.768623|         CRD|        4.5|      1.0|    0.5|       1.2|         0.0|         7.2|   1|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|16780B3E72BAA7A5C...|      CMT|2013-03-27 21:26:02|        1|                 N|2013-03-27 21:29:54|              1|            232.0|          0.7|       -73.99168|      40.739147|        -74.00111|        40.74468|         CSH|        5.0|      0.5|    0.5|       0.0|         0.0|         6.0|   0|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|1E3F1640D7AE96FAD...|      CMT|2013-04-24 21:57:34|        1|                 N|2013-04-24 22:16:29|              1|           1135.0|          5.0|       -74.00161|      40.730717|        -73.95048|       40.780666|         CRD|       18.0|      0.5|    0.5|       3.8|         0.0|        22.8|   1|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-09-30 08:18:49|        1|                 N|2013-09-30 08:25:29|              2|            399.0|          0.7|        -73.9709|       40.79809|         -73.9694|       40.790306|         CRD|        6.0|      0.0|    0.5|       1.3|         0.0|         7.8|   1|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-07 14:24:19|        1|                 N|2013-10-07 14:41:14|              1|           1014.0|          0.9|       -73.97435|      40.762386|       -73.986595|       40.756054|         CSH|       11.0|      0.0|    0.5|       0.0|         0.0|        11.5|   0|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-16 11:54:57|        1|                 N|2013-10-16 11:59:12|              1|            255.0|          0.6|       -73.96133|       40.78015|        -73.96265|       40.773636|         CRD|        5.0|      0.0|    0.5|       1.1|         0.0|         6.6|   1|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-16 13:45:08|        1|                 N|2013-10-16 14:06:27|              2|           1278.0|          6.0|      -73.967064|      40.800983|        -73.97506|       40.741913|         CSH|       21.0|      0.0|    0.5|       0.0|         0.0|        21.5|   0|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-11-06 13:25:34|        1|                 N|2013-11-06 13:38:43|              1|            788.0|          1.9|      -73.970535|       40.76072|        -73.98839|        40.74707|         CRD|       10.5|      0.0|    0.5|      2.75|         0.0|       13.75|   1|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-11-11 11:55:49|        1|                 N|2013-11-11 12:24:06|              1|           1696.0|          3.4|      -73.978584|      40.751293|        -74.01028|       40.716774|         CRD|       19.5|      0.0|    0.5|       4.0|         0.0|        24.0|   1|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-11-27 11:40:57|        1|                 N|2013-11-27 11:46:51|              1|            353.0|          0.7|       -74.00122|      40.720573|       -74.009155|        40.71363|         CRD|        5.5|      0.0|    0.5|       1.0|         0.0|         7.0|   1|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "+--------------------+--------------------+---------+-------------------+---------+------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+----+-----------------+--------------------+-------------------+---------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#looking at the first 10 rows of the data frame to make sure all transformers worked\n",
    "dfMerged.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the columns that have been encoded/transformed into new columns\n",
    "dfMerged = dfMerged.drop('pickup_latitude','pickup_longitude','rate_code','tip_amount','dropoff_latitude', 'dropoff_longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+-------------------+------------------+-------------------+---------------+-----------------+-------------+------------+-----------+---------+-------+------------+------------+----+-----------------+--------------------+-------------------+---------------------+--------------------+\n",
      "|           medallion|        hack_license|vendor_id|    pickup_datetime|store_and_fwd_flag|   dropoff_datetime|passenger_count|trip_time_in_secs|trip_distance|payment_type|fare_amount|surcharge|mta_tax|tolls_amount|total_amount|Tip?|rate_code_encoded|pickup_longitude_bkt|pickup_latitude_bkt|dropoff_longitude_bkt|dropoff_latitude_bkt|\n",
      "+--------------------+--------------------+---------+-------------------+------------------+-------------------+---------------+-----------------+-------------+------------+-----------+---------+-------+------------+------------+----+-----------------+--------------------+-------------------+---------------------+--------------------+\n",
      "|00005007A9F30E289...|16780B3E72BAA7A5C...|      CMT|2013-03-27 19:49:35|                 N|2013-03-27 19:53:00|              1|            204.0|          0.5|         CRD|        4.5|      1.0|    0.5|         0.0|         7.2|   1|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|16780B3E72BAA7A5C...|      CMT|2013-03-27 21:26:02|                 N|2013-03-27 21:29:54|              1|            232.0|          0.7|         CSH|        5.0|      0.5|    0.5|         0.0|         6.0|   0|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|1E3F1640D7AE96FAD...|      CMT|2013-04-24 21:57:34|                 N|2013-04-24 22:16:29|              1|           1135.0|          5.0|         CRD|       18.0|      0.5|    0.5|         0.0|        22.8|   1|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-09-30 08:18:49|                 N|2013-09-30 08:25:29|              2|            399.0|          0.7|         CRD|        6.0|      0.0|    0.5|         0.0|         7.8|   1|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-07 14:24:19|                 N|2013-10-07 14:41:14|              1|           1014.0|          0.9|         CSH|       11.0|      0.0|    0.5|         0.0|        11.5|   0|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-16 11:54:57|                 N|2013-10-16 11:59:12|              1|            255.0|          0.6|         CRD|        5.0|      0.0|    0.5|         0.0|         6.6|   1|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-10-16 13:45:08|                 N|2013-10-16 14:06:27|              2|           1278.0|          6.0|         CSH|       21.0|      0.0|    0.5|         0.0|        21.5|   0|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-11-06 13:25:34|                 N|2013-11-06 13:38:43|              1|            788.0|          1.9|         CRD|       10.5|      0.0|    0.5|         0.0|       13.75|   1|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-11-11 11:55:49|                 N|2013-11-11 12:24:06|              1|           1696.0|          3.4|         CRD|       19.5|      0.0|    0.5|         0.0|        24.0|   1|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "|00005007A9F30E289...|24C122A944FB8EE21...|      CMT|2013-11-27 11:40:57|                 N|2013-11-27 11:46:51|              1|            353.0|          0.7|         CRD|        5.5|      0.0|    0.5|         0.0|         7.0|   1|  (239,[1],[1.0])|                 0.0|                2.0|                  0.0|                 2.0|\n",
      "+--------------------+--------------------+---------+-------------------+------------------+-------------------+---------------+-----------------+-------------+------------+-----------+---------+-------+------------+------------+----+-----------------+--------------------+-------------------+---------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfMerged.show(10) #looking at the first 10 rows of the data frame to make only 21 columns still in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged=dfMerged.drop('features') #removes the column 'features' if it already exists\n",
    "#selects all numeric columns to be combined into column 'features'\n",
    "Cols_to_Select = dfMerged[\"Tip?\", \"total_amount\", \"dropoff_longitude_bkt\", \"dropoff_latitude_bkt\", \"rate_code_encoded\", \"surcharge\", \"tolls_amount\", \"trip_time_in_secs\", \"fare_amount\", \"passenger_count\", \"trip_distance\", \"mta_tax\", \"pickup_latitude_bkt\", \"pickup_longitude_bkt\"]\n",
    "assembler = feat.VectorAssembler(inputCols=Cols_to_Select.columns, outputCol=\"features\") #creates the VectorAssembler object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the VectorAssembler transformation onto the dataframe to create the 'features' column\n",
    "dfMerged=assembler.setHandleInvalid(\"skip\").transform(dfMerged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into train, test, and predict datasets\n",
    "splitted_data = dfMerged.randomSplit([0.8, 0.2], 12345)\n",
    "train_data = splitted_data[0]\n",
    "test_data = splitted_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the logistic regression object \n",
    "logReg_obj = cl.LogisticRegression(\n",
    "    labelCol=\"Tip?\"\n",
    "    , featuresCol = \"features\",\n",
    "    maxIter=10\n",
    ")\n",
    "# using pipeline to run the logistic regression, plus all other objects intially created\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        logReg_obj\n",
    "    ])\n",
    "\n",
    "pipelineModel = pipeline.fit(train_data) #running the model on training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999997401694531, 0.9999997401695326, 0.9999997401694557)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.ml.evaluation as ev\n",
    "#evaluating the model created against test dataset\n",
    "results_logReg = (\n",
    "    pipelineModel\n",
    "    .transform(test_data)\n",
    "    .select('Tip?', 'probability', 'prediction')\n",
    ")\n",
    "\n",
    "evaluator = ev.MulticlassClassificationEvaluator(\n",
    "    predictionCol='prediction'\n",
    "    , labelCol='Tip?')\n",
    "\n",
    "(\n",
    "    evaluator.evaluate(results_logReg)\n",
    "    , evaluator.evaluate(\n",
    "        results_logReg\n",
    "        , {evaluator.metricName: 'weightedPrecision'}\n",
    "    ) \n",
    "    , evaluator.evaluate(\n",
    "        results_logReg\n",
    "        , {evaluator.metricName: 'accuracy'}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the following cells, please provide the requested code and output. Do not change the order and/or structure of the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, print the Area Under the Curve (AUC) for your binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC: 0.9999964360114013\n"
     ]
    }
   ],
   "source": [
    "#saves the model created into a summary variable to extract the area under the ROC curve\n",
    "trainingSummary = pipelineModel.stages[-1].summary\n",
    "\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, provide the code that saves your model your S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the logistic model in a variable and then saving in the S3 bucket\n",
    "logistic_model = pipelineModel.stages[-1]\n",
    "logistic_model.save(\"s3://big-data-bucket-mine/logistic_model_Assignment4/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop() #stopping spark"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
