{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Reviews - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession.builder.appName(\"amazon-reviews-project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for now, only reading reviews for items in the \"Kitchen\" category\n",
    "reviews = sqlContext.read.parquet(\"s3://amazon-reviews-pds/parquet/product_category=Kitchen/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction\n",
    "Obtaining sentiment polarity from review string contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.na.fill({'review_body': '', 'review_headline': ''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf\n",
    "from textblob import TextBlob\n",
    "\n",
    "polarity = udf(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "reviews = reviews.withColumn('headline_polarity', polarity('review_headline'))\\\n",
    "                 .withColumn('body_polarity', polarity('review_body'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4882831"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_parent: string (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- vine: string (nullable = true)\n",
      " |-- verified_purchase: string (nullable = true)\n",
      " |-- review_headline: string (nullable = false)\n",
      " |-- review_body: string (nullable = false)\n",
      " |-- review_date: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- headline_polarity: string (nullable = true)\n",
      " |-- body_polarity: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating \"helpful?\" variable\n",
    "##### A review is helpful if at least 75% of 'total_votes' have been 'helpful_votes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "reviews = reviews.withColumn(\"helpful-ratio\", reviews.helpful_votes/reviews.total_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.withColumn(\"helpful?\", f.when(reviews[\"helpful-ratio\"] > 0.75, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(marketplace='US', customer_id='17050420', review_id='R3QP7FJW6GAB3M', product_id='B007T0CIVS', product_parent='224029078', product_title='Preethi Eco Twin Jar Mixer Grinder, 550-Watt', star_rating=5, helpful_votes=3, total_votes=4, vine='N', verified_purchase='Y', review_headline='Finally something I can use', review_body=\"I always believed that the American blenders went toe to toe with the Indian ones, at least the affordable ones. I was getting tired of the blenders that only seemed to work when water was added or spice mixers that just tossed stuff around without actually grinding anything.<br /><br />Finally here's something that is pretty basic by Indian standards but so very effective. It comes with 2 jar and 4 lids. there are 2 lids for each jar. One adds a lot of room and the other one reduces it. I use the Large lid when I'm blending something like Dosa batter and the smaller lid for chutneys.<br /><br />There's also one extra blade (am not sure if this is for a special purpose or just an extra blade!).<br /><br />The motor is 550W which is not as powerful as the newer 750W Mixers out there but it does the job for half the cost. More value for money if you ask me.<br /><br />The package includes the usual warranty card and manual etc.<br /><br />Shipping was on time and it was well packaged since the mixie came in an extra box with stuffing.<br /><br />All in all a very good purchase for me. Hope it works out for you too.\", review_date=datetime.date(2012, 6, 29), year=2012, headline_polarity='0.0', body_polarity='0.08665532879818595', helpful-ratio=0.75, helpful?=0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.evaluation as ev\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.ml.regression as rg\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.ml.feature as feat\n",
    "import pyspark.ml.classification as cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running bucketizer for pickup_longitude and adding it in the dataset\n",
    "splits = [-float(\"inf\"), 0, 5, float(\"inf\")]\n",
    "\n",
    "bucketizer = feat.Bucketizer(splits=splits, inputCol=\"year\", outputCol=\"year_bkt\")\n",
    "\n",
    "reviews = bucketizer.transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.drop('customer_id','review_id','product_id','parent_product','product title', 'helpful_votes', 'review_headline', 'review_body', 'review_date', 'year', 'helpful-ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- product_parent: string (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- vine: string (nullable = true)\n",
      " |-- verified_purchase: string (nullable = true)\n",
      " |-- headline_polarity: float (nullable = true)\n",
      " |-- body_polarity: float (nullable = true)\n",
      " |-- helpful?: integer (nullable = false)\n",
      " |-- year_bkt: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "reviews = reviews.withColumn(\"headline_polarity\", reviews[\"headline_polarity\"].cast(FloatType()))\n",
    "reviews = reviews.withColumn(\"body_polarity\", reviews[\"body_polarity\"].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=reviews.drop('features') #removes the column 'features' if it already exists\n",
    "#selects all numeric columns to be combined into column 'features'\n",
    "Cols_to_Select = reviews[\"helpful?\", \"star_rating\", \"total_votes\", \"headline_polarity\", \"body_polarity\", \"year_bkt\"]\n",
    "assembler = feat.VectorAssembler(inputCols=Cols_to_Select.columns, outputCol=\"features\") #creates the VectorAssembler object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the VectorAssembler transformation onto the dataframe to create the 'features' column\n",
    "reviews=assembler.setHandleInvalid(\"skip\").transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into train, test, and predict datasets\n",
    "splitted_data = reviews.randomSplit([0.8, 0.2], 111)\n",
    "train_data = splitted_data[0]\n",
    "test_data = splitted_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the logistic regression object \n",
    "logReg_obj = cl.LogisticRegression(\n",
    "    labelCol=\"helpful?\"\n",
    "    , featuresCol = \"features\",\n",
    "    maxIter=5, regParam=0.3, elasticNetParam=0.8\n",
    ")\n",
    "# using pipeline to run the logistic regression, plus all other objects intially created\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        logReg_obj\n",
    "    ])\n",
    "\n",
    "pipelineModel = pipeline.fit(train_data) #running the model on training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary = pipelineModel.stages[-1].summary\n",
    "\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999997401694531, 0.9999997401695326, 0.9999997401694557)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.ml.evaluation as ev\n",
    "#evaluating the model created against test dataset\n",
    "results_logReg = (\n",
    "    pipelineModel\n",
    "    .transform(test_data)\n",
    "    .select('helpful?', 'probability', 'prediction')\n",
    ")\n",
    "\n",
    "evaluator = ev.MulticlassClassificationEvaluator(\n",
    "    predictionCol='prediction'\n",
    "    , labelCol='helpful?')\n",
    "\n",
    "(\n",
    "    evaluator.evaluate(results_logReg)\n",
    "    , evaluator.evaluate(\n",
    "        results_logReg\n",
    "        , {evaluator.metricName: 'weightedPrecision'}\n",
    "    ) \n",
    "    , evaluator.evaluate(\n",
    "        results_logReg\n",
    "        , {evaluator.metricName: 'accuracy'}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
